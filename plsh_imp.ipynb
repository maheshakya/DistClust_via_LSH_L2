{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "from lsh_functions import *\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSH 2-layer small example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a clustering instance - set of points with centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "k = 100\n",
    "d = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma = 1\n",
    "# a = 0.5 # (also epsilon)\n",
    "# c = np.power(np.power(a, 2) * np.power(np.log(n), 3), 0.5)\n",
    "# t = int(np.power(np.log(n), 0.5))\n",
    "# w = t * sigma * np.power(4*np.log(n), 0.5)\n",
    "# n_hashes = int(2/a)\n",
    "\n",
    "# print c\n",
    "# print t \n",
    "# print w\n",
    "# print n_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  20\n",
      "t:  2\n",
      "w:  10\n",
      "n_hashes:  6\n"
     ]
    }
   ],
   "source": [
    "sigma = 1\n",
    "# a = 0.5 # (also epsilon)\n",
    "\n",
    "t = int(np.ceil(np.log(n)/float(np.power(np.log(np.log(n)), 2))))\n",
    "# w = 8 * sigma *np.power(np.log(n), 1.5)\n",
    "w = 10\n",
    "# c = 4 * w / float(np.power(t, 0.5))\n",
    "c = 20\n",
    "n_hashes = int(np.ceil(np.power(np.log(np.log(n)), 2)))\n",
    "\n",
    "print 'c: ', c\n",
    "print 't: ', t \n",
    "print 'w: ', w\n",
    "print 'n_hashes: ', n_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # parameters changed\n",
    "# sigma = 1\n",
    "# a = 0.5 # (also epsilon)\n",
    "# c = np.power(np.power(a, 2) * np.power(np.log(n), 3), 0.5)\n",
    "# t = int(np.power(np.log(n), 0.5))\n",
    "# w = sigma * np.power(np.log(n), 1.5)\n",
    "# n_hashes = int(np.log(n))\n",
    "\n",
    "# print c\n",
    "# print t \n",
    "# print w\n",
    "# print n_hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLSH parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  2\n",
      "multiplier:  3\n",
      "n_grids:  17\n"
     ]
    }
   ],
   "source": [
    "multiplier = 3\n",
    "print 't: ', t\n",
    "print 'multiplier: ', multiplier\n",
    "print 'n_grids: ', int(np.power(2, multiplier*t*np.log(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ratios(n, k):\n",
    "    a = rng.rand(k)\n",
    "    m = n/np.sum(a)\n",
    "    ratios = a*m\n",
    "    ratios = np.array(ratios, dtype=int)\n",
    "    ratios[np.argmin(ratios)] += 1\n",
    "    diff = n - np.sum(ratios)\n",
    "    ratios[np.argmax(ratios)] += + diff\n",
    "    return ratios\n",
    "\n",
    "ratios = create_ratios(n, k)\n",
    "\n",
    "centers = generate_centers(n_centers=k, dim=d, sep=c*sigma)\n",
    "\n",
    "# set cluster std to for cluster radius = \\sigma\n",
    "cluster_std = sigma/(2*np.sqrt(d))\n",
    "\n",
    "pts, clust_ids = make_blobs(ratios[0], d, centers=[centers[0]], cluster_std=cluster_std)\n",
    "\n",
    "for i in range(1, k):\n",
    "    pt, _ = make_blobs(ratios[i], d, centers=[centers[i]], cluster_std=cluster_std)\n",
    "    pts = np.vstack((pts, pt))\n",
    "    clust_ids = np.hstack((clust_ids, np.ones(ratios[i])*i))\n",
    "\n",
    "rnd_order = rng.choice(np.arange(n), n, replace=False)\n",
    "pts = pts[rnd_order]\n",
    "clust_ids = np.array(clust_ids[rnd_order], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diameter of centers:  39.95690610766462\n"
     ]
    }
   ],
   "source": [
    "print 'diameter of centers: ', np.max(pairwise_distances(centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # write data into files\n",
    "# df_pts = pd.DataFrame(pts)\n",
    "# df_clust_ids = pd.DataFrame(clust_ids)\n",
    "\n",
    "# df_pts.to_csv('clustered_pts.txt', sep=' ', header=False, index=False)\n",
    "# df_clust_ids.to_csv('cluster_ids.txt', header=False, index=False)\n",
    "\n",
    "# df_one_pt = pd.DataFrame(np.array(df_pts.ix[3434]).reshape(1, 50))\n",
    "# df_one_pt.to_csv('one_pt.txt', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create grids, hash points and find plsh hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created grids\n",
      "created hash matrices\n",
      "hashed to t dimension\n",
      "finding plsh\n",
      "0  done\n",
      "3121-1-30-200000-1-11-11\n",
      "10000  done\n",
      "1-101-1-30-3-160-17-1-26-11\n",
      "20000  done\n",
      "3020-1-31-3-201-11-1-3303\n",
      "30000  done\n",
      "0-111-1-31-3-160-1500202\n",
      "40000  done\n",
      "7-102-2-21-3-10001-1-2303\n",
      "50000  done\n",
      "0-113-1-21-4-231010-32-13\n",
      "60000  done\n",
      "1-101-1-30-3-160-17-1-26-11\n",
      "70000  done\n",
      "3121-1-32-200000-1-11-11\n",
      "80000  done\n",
      "0015-1-30-3-131030-11-10\n",
      "90000  done\n",
      "15-120-1-31-3-201-11-1-3303\n"
     ]
    }
   ],
   "source": [
    "#create grids\n",
    "shifts = generate_grids(t, multiplier=3)\n",
    "print 'created grids'\n",
    "\n",
    "# create hash matrices\n",
    "hash_matrices = []\n",
    "for i in range(n_hashes):\n",
    "    hash_matrices += [get_hash_matrix(t, d)]\n",
    "print 'created hash matrices'\n",
    "\n",
    "# hash pts into t dimension\n",
    "hashed_values = []\n",
    "for i in range(n_hashes):\n",
    "    hashed_values += [np.dot(hash_matrices[i], pts.transpose()).transpose()]\n",
    "print 'hashed to t dimension'\n",
    "\n",
    "print \"finding plsh\"\n",
    "\n",
    "# find plsh of pts\n",
    "full_hashes = []\n",
    "for i in range(n):\n",
    "    hashed_pts = []\n",
    "    for j in range(n_hashes):\n",
    "        hashed_pts += [hashed_values[j][i]]\n",
    "    full_hashes += [multi_hash(hashed_pts, shifts, w)]\n",
    "    if i%10000 == 0:\n",
    "        print str(i), ' done'\n",
    "        print full_hashes[i]\n",
    "\n",
    "# first level hash - plsh\n",
    "full_hashes = np.array(full_hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_hashes_per_cluster(clust_ids, full_hashes):\n",
    "    clusters = np.unique(clust_ids)\n",
    "    n_hashes_counts = []\n",
    "    for i in range(clusters.shape[0]):\n",
    "        n_hashes_counts += [np.unique(full_hashes[np.where(clust_ids==clusters[i])[0]]).shape[0]]\n",
    "    return clusters, n_hashes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusters_in_buckets(clust_ids, full_hashes):\n",
    "    buckets = np.unique(full_hashes)\n",
    "    clusters = []\n",
    "    for i in range(buckets.shape[0]):\n",
    "        clusters += [clust_ids[np.where(full_hashes==buckets[i])[0]]]\n",
    "    return buckets, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg # of buckets per cluster:  7.97\n"
     ]
    }
   ],
   "source": [
    "clusters, hash_counts = n_hashes_per_cluster(clust_ids, full_hashes)\n",
    "print 'avg # of buckets per cluster: ', np.mean(hash_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of buckets:  797\n",
      "avg # of clusters in a bucket:  1.0\n"
     ]
    }
   ],
   "source": [
    "buckets, clusters = clusters_in_buckets(clust_ids, full_hashes)\n",
    "print 'total # of buckets: ', buckets.shape[0]\n",
    "\n",
    "bucket_stats = []\n",
    "for i in range(len(clusters)):\n",
    "    a, b = np.unique(clusters[i], return_counts=True)    \n",
    "    max_c_id = np.argmax(b)\n",
    "    max_c = a[max_c_id]\n",
    "    n_clusters = a.shape[0]\n",
    "    bucket_stats += [[n_clusters, max_c]]\n",
    "bucket_stats = np.array(bucket_stats)\n",
    "\n",
    "#print bucket_stats\n",
    "print 'avg # of clusters in a bucket: ', np.mean(bucket_stats[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg pts in a bucket:  125.47051442910916\n",
      "max pts in a bucket:  1898\n",
      "min pts in a bucket:  1\n"
     ]
    }
   ],
   "source": [
    "# avg # of pts in a bucket\n",
    "distinct_buckets = np.unique(full_hashes)\n",
    "bucket_counts = []\n",
    "for val in distinct_buckets:\n",
    "    bucket_counts += [np.where(full_hashes==val)[0].shape[0]]\n",
    "print 'avg pts in a bucket: ', np.mean(bucket_counts)\n",
    "print 'max pts in a bucket: ', np.max(bucket_counts)\n",
    "print 'min pts in a bucket: ', np.min(bucket_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 5\n",
    "n_groups = L*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_hashes = []\n",
    "for i in range(len(full_hashes)):\n",
    "    second_hashes += [second_hash(full_hashes[i], n_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg pts in a group:  245.09803921568627\n",
      "max pts in a group:  1898\n",
      "min pts in a group:  1\n"
     ]
    }
   ],
   "source": [
    "distinct_groups = np.unique(second_hashes)\n",
    "group_counts = []\n",
    "for val in distinct_groups:\n",
    "    group_counts += [np.where(second_hashes==val)[0].shape[0]]\n",
    "print 'avg pts in a group: ', np.mean(group_counts)\n",
    "print 'max pts in a group: ', np.max(group_counts)\n",
    "print 'min pts in a group: ', np.min(group_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
